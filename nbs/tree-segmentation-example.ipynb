{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b10bc6",
   "metadata": {},
   "source": [
    "# Tree-Based Segmentation for Error Analysis\n",
    "\n",
    "This notebook demonstrates how to use the DecisionTreeSegmentation class to identify and analyze error patterns in your model predictions using a tree-based approach.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When analyzing model performance, it's useful to identify regions in the feature space where your model is underperforming. The DecisionTreeSegmentation class helps segment the feature space based on error patterns, and the plotting functions help visualize these segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tab_right.plotting.plot_segmentations import plot_dt_segmentation, plot_dt_segmentation_with_stats\n",
    "\n",
    "# Import the DecisionTreeSegmentation class and plotting functions\n",
    "from tab_right.segmentations import DecisionTreeSegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee41bd",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "First, let's generate some synthetic data with a non-linear pattern that will be challenging for the model to learn perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35318f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic dataset with known patterns\n",
    "n_samples = 1000\n",
    "X = pd.DataFrame({\n",
    "    \"feature1\": np.random.uniform(-3, 3, n_samples),\n",
    "    \"feature2\": np.random.uniform(-3, 3, n_samples),\n",
    "    \"feature3\": np.random.normal(0, 1, n_samples),\n",
    "})\n",
    "\n",
    "# Create a target with a complex non-linear pattern\n",
    "noise = np.random.normal(0, 0.5, n_samples)\n",
    "y = 2 * np.sin(X[\"feature1\"]) + X[\"feature2\"] ** 2 + 0.5 * X[\"feature3\"] + noise\n",
    "\n",
    "# Display the first few rows of the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44310123",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "\n",
    "Now let's train a RandomForestRegressor on this data and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a random forest model (intentionally underfitting to create meaningful error patterns)\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29272aea",
   "metadata": {},
   "source": [
    "## Visualize Error Distribution\n",
    "\n",
    "Let's first visualize the distribution of errors to understand the overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d014839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors\n",
    "errors = np.abs(y_test - y_pred)\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors, bins=30, alpha=0.7, color=\"skyblue\")\n",
    "plt.axvline(np.mean(errors), color=\"red\", linestyle=\"dashed\", linewidth=1, label=f\"Mean Error: {np.mean(errors):.2f}\")\n",
    "plt.axvline(\n",
    "    np.median(errors), color=\"green\", linestyle=\"dashed\", linewidth=1, label=f\"Median Error: {np.median(errors):.2f}\"\n",
    ")\n",
    "plt.title(\"Distribution of Absolute Errors\")\n",
    "plt.xlabel(\"Absolute Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb38183",
   "metadata": {},
   "source": [
    "## Apply Tree-Based Segmentation\n",
    "\n",
    "Now let's use the DecisionTreeSegmentation class to identify regions in the feature space where our model has higher errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree segmentation\n",
    "dt_seg = DecisionTreeSegmentation(max_depth=4, min_samples_leaf=20)\n",
    "\n",
    "# Fit the model to analyze errors using the first two features\n",
    "dt_seg.fit(X_test, y_test, y_pred, feature_names=[\"feature1\", \"feature2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d776d8",
   "metadata": {},
   "source": [
    "## Visualize Error Segments with Plotly\n",
    "\n",
    "Now let's use the plotting functions from the plotting subpackage to create interactive visualizations of the error segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c82e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive visualization using Plotly\n",
    "fig_plotly = plot_dt_segmentation(dt_seg, cmap=\"YlOrRd\", figsize=(800, 600))\n",
    "fig_plotly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b409928",
   "metadata": {},
   "source": [
    "## Combined Visualization with Statistics\n",
    "\n",
    "Let's create a more comprehensive visualization that shows both the error heatmap and statistics about the top error segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined visualization with both heatmap and segment statistics\n",
    "fig_combined = plot_dt_segmentation_with_stats(dt_seg, n_top_segments=5, cmap=\"Viridis\", figsize=(1000, 500))\n",
    "fig_combined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e70a75",
   "metadata": {},
   "source": [
    "## Get Segment Statistics\n",
    "\n",
    "Let's get statistical information about the top error segments to better understand where our model is underperforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics for the top 5 error segments\n",
    "segment_stats = dt_seg.get_segment_stats(n_segments=5)\n",
    "segment_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d763d4f",
   "metadata": {},
   "source": [
    "## Get Segmented Data with Segment IDs\n",
    "\n",
    "We can also get the original data with segment assignments, which can be useful for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segmented data with segment IDs and error statistics\n",
    "segmented_df = dt_seg.get_segment_df(n_segments=5)\n",
    "segmented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cadb5",
   "metadata": {},
   "source": [
    "## Extract Decision Rules\n",
    "\n",
    "Finally, let's extract the decision rules that define the high-error segments. This gives us interpretable conditions to understand which feature combinations lead to higher prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decision rules for top segments\n",
    "rules = dt_seg.get_decision_rules(n_segments=3)\n",
    "\n",
    "# Format and display the rules\n",
    "for segment_id, rule_list in rules.items():\n",
    "    print(f\"Segment {segment_id} Rules:\")\n",
    "    for rule in rule_list:\n",
    "        print(f\"  {rule['feature']} {rule['operator']} {rule['threshold']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7a25d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The tree-based segmentation analysis helps identify regions in the feature space where our model has high prediction errors. By visualizing these regions using heatmaps and extracting interpretable decision rules, we can better understand the model's limitations and potentially improve its performance through targeted feature engineering or model adjustments.\n",
    "\n",
    "The new Plotly visualization feature provides an interactive way to explore error patterns, making it easier to analyze and communicate model performance issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
