{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cd104d",
   "metadata": {},
   "source": [
    "# CatBoost Model: Drift & Segmentation Analysis\n",
    "This notebook demonstrates how to train a CatBoost model, analyze drift, and perform segmentation analysis with interactive Plotly visualizations using the `tab-right` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbf652c039a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Colab or a fresh environment\n",
    "# !pip install catboost plotly pandas scikit-learn tab-right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be18540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859d1d3",
   "metadata": {},
   "source": [
    "## Load Example Dataset\n",
    "We'll use the UCI Adult dataset (census income) from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8de75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "df = data.frame.copy()\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "df = df.dropna()  # Drop missing for simplicity\n",
    "df[\"target\"] = (df[\"class\"] == \">50K\").astype(int)\n",
    "df = df.drop(columns=[\"class\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da731ac",
   "metadata": {},
   "source": [
    "## Split Data: Reference vs. Current\n",
    "We'll simulate drift by splitting the data by time (first 70% as reference, last 30% as current)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(0.7 * len(df))\n",
    "df_ref = df.iloc[:split_idx].reset_index(drop=True)\n",
    "df_cur = df.iloc[split_idx:].reset_index(drop=True)\n",
    "print(f\"Reference: {df_ref.shape}, Current: {df_cur.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf81f2",
   "metadata": {},
   "source": [
    "## Train CatBoost Model\n",
    "We'll train on the reference data and predict on the current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df_ref.select_dtypes(include=\"category\").columns.tolist() + [\n",
    "    col for col in df_ref.columns if df_ref[col].dtype == \"object\"\n",
    "]\n",
    "cat_features = list(set(cat_features) - set([\"target\"]))\n",
    "X_ref = df_ref.drop(columns=[\"target\"])\n",
    "y_ref = df_ref[\"target\"]\n",
    "X_cur = df_cur.drop(columns=[\"target\"])\n",
    "y_cur = df_cur[\"target\"]\n",
    "model = CatBoostClassifier(cat_features=cat_features)\n",
    "model.fit(X_ref, y_ref)\n",
    "y_pred = model.predict(X_cur)\n",
    "print(\"Accuracy on current:\", accuracy_score(y_cur, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d808e",
   "metadata": {},
   "source": [
    "## Segmentation Analysis\n",
    "Let's segment the predictions by features and visualize the results using tab_right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules from tab_right\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from tab_right.plotting.plot_segmentations import DoubleSegmPlotting, plot_single_segmentation\n",
    "from tab_right.segmentations.double_seg import DoubleSegmentationImp\n",
    "from tab_right.segmentations.find_seg import FindSegmentationImp\n",
    "\n",
    "# Import specific modules from tab_right\n",
    "from tab_right.task_detection import detect_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509eb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions with probabilities\n",
    "y_pred_proba = model.predict_proba(X_cur)\n",
    "\n",
    "# Create a DataFrame with features, true labels, and predictions\n",
    "df_analysis = X_cur.copy()\n",
    "df_analysis[\"target\"] = y_cur\n",
    "df_analysis[\"pred_class\"] = y_pred\n",
    "df_analysis[\"pred_prob_0\"] = y_pred_proba[:, 0]\n",
    "df_analysis[\"pred_prob_1\"] = y_pred_proba[:, 1]\n",
    "\n",
    "# Detect task type (should be binary classification)\n",
    "task_type = detect_task(y_cur)\n",
    "print(f\"Detected task type: {task_type.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c9d34",
   "metadata": {},
   "source": [
    "### Define Error Metrics\n",
    "Let's define some error metrics for our segmentation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_log_loss(y_true, y_pred_df):\n",
    "    \"\"\"Calculate binary log loss for each row.\"\"\"\n",
    "    y_pred = y_pred_df[\"pred_prob_1\"]\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "\n",
    "def binary_error(y_true, y_pred_df):\n",
    "    \"\"\"Calculate binary classification error (0/1 loss) for each row.\"\"\"\n",
    "    y_pred = y_pred_df[\"pred_class\"]\n",
    "    return (y_true != y_pred).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460172d3",
   "metadata": {},
   "source": [
    "### Single Feature Segmentation\n",
    "Let's analyze how model performance varies across different segments of a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76167423ce2d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the segmentation finder\n",
    "segmentation_finder = FindSegmentationImp(\n",
    "    df=df_analysis, label_col=\"target\", prediction_col=[\"pred_prob_0\", \"pred_prob_1\"]\n",
    ")\n",
    "\n",
    "# Create a decision tree model for segmentation\n",
    "tree_model = DecisionTreeRegressor(max_depth=3, min_samples_leaf=100)\n",
    "\n",
    "# Features to analyze\n",
    "features_to_analyze = [\"age\", \"education-num\", \"hours-per-week\", \"capital-gain\"]\n",
    "\n",
    "# Analyze each feature and visualize\n",
    "for feature in features_to_analyze:\n",
    "    print(f\"\\nAnalyzing feature: {feature}\")\n",
    "\n",
    "    # Find segmentation\n",
    "    segments = segmentation_finder(feature, binary_log_loss, tree_model)\n",
    "    print(f\"Found {len(segments)} segments\")\n",
    "\n",
    "    # Display the segments\n",
    "    display(segments)\n",
    "\n",
    "    # Plot the segmentation\n",
    "    fig = plot_single_segmentation(segments)\n",
    "    fig.update_layout(title=f\"Log Loss by {feature} Segments\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38932d",
   "metadata": {},
   "source": [
    "### Double Feature Segmentation\n",
    "Now let's analyze how model performance varies across segments defined by two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ba613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the double segmentation\n",
    "double_segmentation = DoubleSegmentationImp(segmentation_finder)\n",
    "\n",
    "# Define feature pairs to analyze\n",
    "feature_pairs = [(\"age\", \"education-num\"), (\"age\", \"hours-per-week\"), (\"education-num\", \"hours-per-week\")]\n",
    "\n",
    "# Analyze each feature pair and visualize\n",
    "for feature1, feature2 in feature_pairs:\n",
    "    print(f\"\\nAnalyzing feature pair: {feature1} and {feature2}\")\n",
    "\n",
    "    # Find double segmentation\n",
    "    double_segments = double_segmentation(feature1, feature2, binary_log_loss, tree_model)\n",
    "    print(f\"Found {len(double_segments)} segment combinations\")\n",
    "\n",
    "    # Display the segments\n",
    "    display(double_segments.head())\n",
    "\n",
    "    # Create double segmentation plotter\n",
    "    double_plotter = DoubleSegmPlotting(df=double_segments, metric_name=\"Log Loss\")\n",
    "\n",
    "    # Plot the heatmap\n",
    "    heatmap_fig = double_plotter.plotly_heatmap()\n",
    "    heatmap_fig.update_layout(\n",
    "        title=f\"Log Loss Heatmap: {feature1} vs {feature2}\", xaxis_title=feature1, yaxis_title=feature2\n",
    "    )\n",
    "    heatmap_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae06725",
   "metadata": {},
   "source": [
    "## Performance Analysis by Features\n",
    "Let's take a deeper look at how the model performs across categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38940bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Select some categorical features to analyze\n",
    "cat_features_to_analyze = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\"]\n",
    "\n",
    "for cat_feature in cat_features_to_analyze:\n",
    "    # Group by the categorical feature\n",
    "    grouped = df_analysis.groupby(cat_feature).agg({\n",
    "        \"target\": [\"count\", \"mean\"],\n",
    "        \"pred_class\": lambda x: accuracy_score(df_analysis.loc[x.index, \"target\"], x),\n",
    "        \"pred_prob_1\": lambda x: roc_auc_score(df_analysis.loc[x.index, \"target\"], x),\n",
    "    })\n",
    "\n",
    "    # Flatten the column hierarchy\n",
    "    grouped.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0] for col in grouped.columns]\n",
    "    grouped = grouped.rename(columns={\"pred_class_<lambda>\": \"accuracy\", \"pred_prob_1_<lambda>\": \"auc\"})\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    # Plot accuracy by category\n",
    "    fig = px.bar(\n",
    "        grouped,\n",
    "        x=cat_feature,\n",
    "        y=\"accuracy\",\n",
    "        color=\"target_count\",\n",
    "        hover_data=[\"target_mean\", \"auc\", \"target_count\"],\n",
    "        labels={\"accuracy\": \"Accuracy\", \"target_count\": \"Sample Count\", \"target_mean\": \"Positive Rate\", \"auc\": \"AUC\"},\n",
    "        title=f\"Model Performance by {cat_feature}\",\n",
    "    )\n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fcb4d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
