{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cd104d",
   "metadata": {},
   "source": [
    "# Double Segmentation Analysis Example\n",
    "This notebook demonstrates how to perform double segmentation analysis with interactive Plotly visualizations using the `tab-right` package, using dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbf652c039a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Colab or a fresh environment\n",
    "# !pip install plotly pandas scikit-learn tab-right numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be18540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Import required modules from tab_right\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859d1d3",
   "metadata": {},
   "source": [
    "## Load Example Dataset & Create Dummy Data\n",
    "We'll use the UCI Adult dataset for features and generate dummy target and prediction columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8de75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "df = data.frame.copy()\n",
    "df = df.sample(n=5000, random_state=42).reset_index(drop=True)  # Use a sample\n",
    "df = df.dropna()  # Drop missing for simplicity\n",
    "\n",
    "# Create dummy target and prediction columns\n",
    "np.random.seed(42)\n",
    "df[\"target\"] = np.random.randint(0, 2, size=len(df))\n",
    "df[\"prediction\"] = np.random.rand(len(df))  # Dummy probability prediction\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "df_analysis = df[\n",
    "    [\"age\", \"education-num\", \"hours-per-week\", \"target\", \"prediction\"]\n",
    "].copy()  # Add more features if needed\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38932d",
   "metadata": {},
   "source": [
    "### Double Feature Segmentation\n",
    "Analyze how a dummy metric varies across segments defined by two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020fec6eb0c3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score  # Import accuracy_score\n",
    "\n",
    "\n",
    "def safe_roc_auc_score(y_true, y_pred):\n",
    "    \"\"\"Calculate ROC AUC score with error handling for single-class data.\"\"\"\n",
    "    try:\n",
    "        if len(set(y_true)) < 2:\n",
    "            return None  # Not enough classes for ROC AUC\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38940bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some categorical features to analyze\n",
    "cat_features_to_analyze = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\"]\n",
    "\n",
    "for cat_feature in cat_features_to_analyze:\n",
    "    # Group by the categorical feature\n",
    "    grouped = df_analysis.groupby(cat_feature).agg({\n",
    "        \"target\": [\"count\", \"mean\"],\n",
    "        # Use accuracy_score correctly\n",
    "        \"pred_class\": lambda x: accuracy_score(df_analysis.loc[x.index, \"target\"], x),\n",
    "        \"pred_prob_1\": lambda x: safe_roc_auc_score(df_analysis.loc[x.index, \"target\"], x),\n",
    "    })\n",
    "\n",
    "    # Flatten the column hierarchy\n",
    "    grouped.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0] for col in grouped.columns]\n",
    "    grouped = grouped.rename(columns={\"pred_class_<lambda>\": \"accuracy\", \"pred_prob_1_<lambda>\": \"auc\"})\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    # Filter out categories with no AUC score for better visualization\n",
    "    grouped_filtered = grouped[grouped[\"auc\"].notna()]\n",
    "\n",
    "    # Plot accuracy by category\n",
    "    if not grouped_filtered.empty:\n",
    "        fig = px.bar(\n",
    "            grouped_filtered,\n",
    "            x=cat_feature,\n",
    "            y=\"accuracy\",\n",
    "            color=\"target_count\",\n",
    "            hover_data=[\"target_mean\", \"auc\", \"target_count\"],\n",
    "            labels={\n",
    "                \"accuracy\": \"Accuracy\",\n",
    "                \"target_count\": \"Sample Count\",\n",
    "                \"target_mean\": \"Positive Rate\",\n",
    "                \"auc\": \"AUC\",\n",
    "            },\n",
    "            title=f\"Model Performance by {cat_feature}\",\n",
    "        )\n",
    "        fig.update_layout(xaxis_tickangle=-45)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabcde6",
   "metadata": {},
   "source": [
    "End of demonstration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
